=====================================================================================================================================================================
Layer (type:depth-idx)                                            Output Shape                                       Param #
=====================================================================================================================================================================
PeftModelForCausalLM                                              [1, 42, 32000]                                     --
├─LoraModel: 1-1                                                  [1, 42, 32000]                                     --
│    └─ThirdLlamaForCausalLM: 2-1                                 --                                                 --
│    │    └─ThirdLlamaModel: 3-1                                  [1, 42, 4096]                                      131,072,000
│    │    │    └─ModuleList: 4-1                                  --                                                 --
│    │    │    │    └─LlamaDecoderLayer: 5-1                      [1, 42, 4096]                                      --
│    │    │    │    │    └─LlamaRMSNorm: 6-1                      [1, 42, 4096]                                      (4,096)
│    │    │    │    │    └─LlamaAttention: 6-2                    [1, 42, 4096]                                      --
│    │    │    │    │    │    └─Linear: 7-1                       [1, 42, 4096]                                      16,777,216
│    │    │    │    │    │    │    └─ModuleDict: 8-1              --                                                 --
│    │    │    │    │    │    │    │    └─Dropout: 9-1            [1, 42, 4096]                                      --
│    │    │    │    │    │    │    └─ModuleDict: 8-2              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-2             [1, 42, 16]                                        (65,536)
│    │    │    │    │    │    │    └─ModuleDict: 8-3              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-3             [1, 42, 4096]                                      (65,536)
│    │    │    │    │    │    └─Linear: 7-2                       [1, 42, 4096]                                      16,777,216
│    │    │    │    │    │    │    └─ModuleDict: 8-4              --                                                 --
│    │    │    │    │    │    │    │    └─Dropout: 9-4            [1, 42, 4096]                                      --
│    │    │    │    │    │    │    └─ModuleDict: 8-5              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-5             [1, 42, 16]                                        (65,536)
│    │    │    │    │    │    │    └─ModuleDict: 8-6              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-6             [1, 42, 4096]                                      (65,536)
│    │    │    │    │    │    └─Linear: 7-3                       [1, 42, 4096]                                      16,777,216
│    │    │    │    │    │    │    └─ModuleDict: 8-7              --                                                 --
│    │    │    │    │    │    │    │    └─Dropout: 9-7            [1, 42, 4096]                                      --
│    │    │    │    │    │    │    └─ModuleDict: 8-8              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-8             [1, 42, 16]                                        (65,536)
│    │    │    │    │    │    │    └─ModuleDict: 8-9              --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-9             [1, 42, 4096]                                      (65,536)
│    │    │    │    │    │    └─LlamaRotaryEmbedding: 7-4         [1, 1, 42, 128]                                    --
│    │    │    │    │    │    └─Linear: 7-5                       [1, 42, 4096]                                      16,777,216
│    │    │    │    │    │    │    └─ModuleDict: 8-10             --                                                 --
│    │    │    │    │    │    │    │    └─Dropout: 9-10           [1, 42, 4096]                                      --
│    │    │    │    │    │    │    └─ModuleDict: 8-11             --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-11            [1, 42, 16]                                        (65,536)
│    │    │    │    │    │    │    └─ModuleDict: 8-12             --                                                 --
│    │    │    │    │    │    │    │    └─Linear: 9-12            [1, 42, 4096]                                      (65,536)
│    │    │    │    │    └─LlamaRMSNorm: 6-3                      [1, 42, 4096]                                      (4,096)
│    │    │    │    │    └─LlamaMLP: 6-4                          [1, 42, 4096]                                      --
│    │    │    │    │    │    └─Linear: 7-6                       [1, 42, 11008]                                     (45,088,768)
│    │    │    │    │    │    └─SiLUActivation: 7-7               [1, 42, 11008]                                     --
│    │    │    │    │    │    └─Linear: 7-8                       [1, 42, 11008]                                     (45,088,768)
│    │    │    │    │    │    └─Linear: 7-9                       [1, 42, 4096]                                      (45,088,768)
│    │    │    └─LlamaRMSNorm: 4-2                                [1, 42, 4096]                                      (4,096)
│    │    └─Linear: 3-2                                           [1, 42, 32000]                                     (131,072,000)
=====================================================================================================================================================================
Total params: 465,055,744
Trainable params: 0
Non-trainable params: 465,055,744
Total mult-adds (M): 266.87
=====================================================================================================================================================================
Input size (MB): 0.34
Forward/backward pass size (MB): 14.59
Params size (MB): 533.75
Estimated Total Size (MB): 548.68
=====================================================================================================================================================================