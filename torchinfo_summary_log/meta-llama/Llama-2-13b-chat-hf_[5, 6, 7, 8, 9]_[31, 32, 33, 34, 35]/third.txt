Third  : [31, 32, 33, 34, 35, 36, 37, 38, 39]

ThirdLlamaForCausalLM(
  (model): ThirdLlamaModel(
    (embed_tokens): Embedding(32000, 5120, padding_idx=0)
    (layers): ModuleList(
      (0-30): 31 x ExtendedIdentity()
      (31-39): 9 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)
          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)
          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)
          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)
          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)
          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)
  (embed_tokens): ExtendedIdentity()
)

===========================================================================================================================================================
Layer (type:depth-idx)                                  Output Shape                                       Param #
===========================================================================================================================================================
ThirdLlamaForCausalLM                                   [1, 40, 50, 128]                                   --
├─ThirdLlamaModel: 1-1                                  [1, 40, 50, 128]                                   163,840,000
│    └─ModuleList: 2-1                                  --                                                 --
│    │    └─LlamaDecoderLayer: 3-1                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-1                      [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-2                    [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-1                       [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-2                       [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-3                       [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-4         [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-5                       [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-3                      [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-4                          [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-6                       [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-7               [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-8                       [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-9                       [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-2                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-5                      [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-6                    [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-10                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-11                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-12                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-13        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-14                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-7                      [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-8                          [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-15                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-16              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-17                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-18                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-3                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-9                      [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-10                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-19                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-20                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-21                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-22        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-23                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-11                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-12                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-24                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-25              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-26                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-27                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-4                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-13                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-14                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-28                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-29                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-30                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-31        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-32                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-15                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-16                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-33                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-34              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-35                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-36                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-5                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-17                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-18                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-37                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-38                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-39                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-40        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-41                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-19                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-20                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-42                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-43              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-44                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-45                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-6                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-21                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-22                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-46                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-47                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-48                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-49        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-50                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-23                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-24                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-51                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-52              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-53                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-54                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-7                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-25                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-26                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-55                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-56                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-57                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-58        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-59                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-27                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-28                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-60                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-61              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-62                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-63                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-8                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-29                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-30                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-64                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-65                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-66                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-67        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-68                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-31                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-32                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-69                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-70              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-71                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-72                      [1, 50, 5120]                                      70,778,880
│    │    └─LlamaDecoderLayer: 3-9                      [1, 50, 5120]                                      --
│    │    │    └─LlamaRMSNorm: 4-33                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaAttention: 4-34                   [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-73                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-74                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─Linear: 5-75                      [1, 50, 5120]                                      26,214,400
│    │    │    │    └─LlamaRotaryEmbedding: 5-76        [1, 1, 50, 128]                                    --
│    │    │    │    └─Linear: 5-77                      [1, 50, 5120]                                      26,214,400
│    │    │    └─LlamaRMSNorm: 4-35                     [1, 50, 5120]                                      5,120
│    │    │    └─LlamaMLP: 4-36                         [1, 50, 5120]                                      --
│    │    │    │    └─Linear: 5-78                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─SiLUActivation: 5-79              [1, 50, 13824]                                     --
│    │    │    │    └─Linear: 5-80                      [1, 50, 13824]                                     70,778,880
│    │    │    │    └─Linear: 5-81                      [1, 50, 5120]                                      70,778,880
│    └─LlamaRMSNorm: 2-2                                [1, 50, 5120]                                      5,120
├─Linear: 1-2                                           [1, 50, 32000]                                     163,840,000
===========================================================================================================================================================
Total params: 3,182,525,440
Trainable params: 3,182,525,440
Non-trainable params: 0
Total mult-adds (G): 3.02
===========================================================================================================================================================
Input size (MB): 0.51
Forward/backward pass size (MB): 243.40
Params size (MB): 12074.74
Estimated Total Size (MB): 12318.66
===========================================================================================================================================================